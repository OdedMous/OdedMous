## Hi there üëã

<!--
**OdedMous/OdedMous** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->

# Selected Projects

## [Text Classification with Siamese Network](https://github.com/OdedMous/Medical-Text-Classification) 
In this project, I developed an NLP classifier for detecting medical domains in texts using a Siamese Neural Network.

<img src="https://github.com/OdedMous/Medical-Transcriptions-Classification/blob/main/images/Medical_Transcription.jpg" width="500" height="250" />


## [Cross-Task Learning for Low-Resource NLP](https://github.com/OdedMous/Cross-Task-Learning-for-Low-Resource-NLP) 
Humans generalize knowledge across different domains. For example, learning to play the piano enhances hand-eye coordination, which can improve skills in other activities like basketball. Inspired by this, we propose an approach to address the problem of a shortage of annotated data in specialized NLP tasks, such as medicine. We propose a multi-head BERT-based model, which is trained simultaneously on both the main task and supporting tasks, in order to perform cross-task knowledge transfer.

NLP models are hungry for annotated data, which are often costly and difficult to obtain, especially in specialized fields like medicine. To tackle this problem, we propose training a model on both a primary NLP task and related ‚Äúsupporting tasks,‚Äù leveraging cross-task knowledge transfer. Unlike traditional multi-task learning, our approach is solely focused on improving the 


## [Differentially Private Decoding in LLMs](https://github.com/OdedMous/DP-Decoding-in-LLM) 

Large Language Models are pre-trained on vast public data collected from the Internet, which likely contains private or sensitive information. Combined with the fact that large models tend to memorize training data, this scenario poses a potential risk of data leakage.

In this project, I reimplemented a decoding method that ensures privacy with high probability, based on the paper "Differentially Private Decoding in Large Language Models" (Majmudar et al., 2022).


# Blogs
